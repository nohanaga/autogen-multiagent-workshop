{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd4fdc18",
   "metadata": {},
   "source": [
    "# GraphFlow Advanced(Workflows)\n",
    "## AutoGen の SocietyOfMindAgent によるネスト型マルチエージェント構成\n",
    "\n",
    "より複雑なマルチエージェント構成を考えてみます。AutoGen を愛用しているユーザーにとっては、`GraphFlow` と既存の自律性の高い `SelectorGroupChat` や `RoundRobinGroupChat` と組み合わせてみたいと考えるのは自然かと思います。\n",
    "\n",
    "![](./img/002.png)\n",
    "\n",
    "今回はこのようなエージェントを実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ec14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U \"autogen-agentchat\"\n",
    "#!pip install \"autogen-ext[mcp,openai,azure]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c61a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List  \n",
    "import os  \n",
    "from dotenv import load_dotenv  \n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent  \n",
    "from autogen_agentchat.teams import DiGraphBuilder, GraphFlow\n",
    "\n",
    "from autogen_core import CancellationToken  \n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient  \n",
    "from autogen_ext.tools.mcp import SseServerParams, mcp_server_tools  \n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48747bd4",
   "metadata": {},
   "source": [
    "## OpenTelemetry によるトレーサーのセット\n",
    "マルチエージェントのデバッグには OpenTelemetry によるトレーサーを利用すると便利。`OpenAIInstrumentor` を使用して OpenAI コールをキャプチャできます。ここではトレース UI として [Jaeger](https://www.jaegertracing.io/download/) を使用しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d823abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp opentelemetry-instrumentation-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2087c39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry import trace\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "service_name = \"autogen\"\n",
    "\n",
    "# OTLPエクスポーターの設定 (gRPC経由で送信)\n",
    "otlp_exporter = OTLPSpanExporter(\n",
    "    endpoint=\"http://localhost:4317\",  # JaegerのgRPCエンドポイント\n",
    ")\n",
    "tracer_provider = TracerProvider(resource=Resource({\"service.name\": service_name}))\n",
    "    \n",
    "# トレーサープロバイダーの設定\n",
    "trace.set_tracer_provider(tracer_provider)\n",
    "\n",
    "# バッチスパンプロセッサーを設定\n",
    "span_processor = BatchSpanProcessor(otlp_exporter)\n",
    "tracer_provider.add_span_processor(span_processor)\n",
    "\n",
    "# トレーサーを取得\n",
    "tracer = tracer_provider.get_tracer(service_name)\n",
    "\n",
    "OpenAIInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_server_uri = os.getenv(\"MCP_SERVER_URI\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_model = os.getenv(\"AZURE_OPENAI_MODEL\")\n",
    "azure_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "openai_model_name = os.getenv(\"OPENAI_MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de35e7a0",
   "metadata": {},
   "source": [
    "## Tools の定義(MCP over SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8de4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_params = SseServerParams(  \n",
    "    url=mcp_server_uri,  \n",
    "    headers={\"Content-Type\": \"application/json\"},  \n",
    "    timeout=30  \n",
    ")  \n",
    "\n",
    "# Fetch tools (async)  \n",
    "tools = await mcp_server_tools(server_params)  \n",
    "print(f\"Number of Tools: {len(tools)}\")\n",
    "# Set up the OpenAI/Azure model client  \n",
    "model_client = AzureOpenAIChatCompletionClient(  \n",
    "    api_key=azure_openai_key,  \n",
    "    azure_endpoint=azure_openai_endpoint,  \n",
    "    api_version=api_version,  \n",
    "    azure_deployment=azure_deployment,  \n",
    "    model=openai_model_name,  \n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8deed6e",
   "metadata": {},
   "source": [
    "## チーム編成\n",
    "`RoundRobinGroupChat` で 2 つの井戸端会議的パターンを定義。例として批判的評価チームと肯定的評価チームに分けてみました。実際は各 `AssistantAgent` には適切なロールとナレッジ、アクションをアタッチします。今回は簡単のため、`TextMessageTermination(\"critic_agent3\")` のようにして会話終了条件を 3 人目のエージェントが発言したら終了するようにしました。\n",
    "\n",
    "![](./img/001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4e9859",
   "metadata": {},
   "source": [
    "## エージェント定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b15d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "from autogen_agentchat.agents import AssistantAgent, SocietyOfMindAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.conditions import TextMessageTermination  \n",
    "\n",
    "# Create the final reviewer agent\n",
    "writer_agent = AssistantAgent(\n",
    "    \"writer_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"あなたはプロの小説家です。魅力的な文章を完結なタッチで書くことができます。\",\n",
    ")\n",
    "\n",
    "# Create the final reviewer agent\n",
    "critic_agent1 = AssistantAgent(\n",
    "    \"critic_agent1\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"作成された文章を批判的な観点から評価し、改善点を提案すること。\",\n",
    ")\n",
    "\n",
    "# Create the final reviewer agent\n",
    "critic_agent2 = AssistantAgent(\n",
    "    \"critic_agent2\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"あなたはリスクアドバイザーです。作成された文章のアイデア被りやSMS等で炎上しないかどうかを評価し、改善点を提案すること。\",\n",
    ")\n",
    "\n",
    "# Create the final reviewer agent\n",
    "critic_agent3 = AssistantAgent(\n",
    "    \"critic_agent3\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"あなたは法学のスペシャリストです。作成された文章を法的観点から評価し、改善点を提案すること。\",\n",
    ")\n",
    "\n",
    "# add agents to array\n",
    "critic_agents: List[AssistantAgent] = [\n",
    "    critic_agent1,\n",
    "    critic_agent2,\n",
    "    critic_agent3,\n",
    "]\n",
    "\n",
    "termination_condition = TextMessageTermination(\"critic_agent3\") #3人目が発言したら終了\n",
    "critic_team = RoundRobinGroupChat(critic_agents, termination_condition=termination_condition)\n",
    "\n",
    "\n",
    "# Create the final reviewer agent\n",
    "progressive_agent1 = AssistantAgent(\n",
    "    \"progressive_agent1\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"作成された文章を肯定的な観点から評価し、改善点を提案すること。\",\n",
    ")\n",
    "\n",
    "# Create the final reviewer agent\n",
    "progressive_agent2 = AssistantAgent(\n",
    "    \"progressive_agent2\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"あなたは先進的なアイデアを持っています。作成された文章を肯定的に評価し、品質を向上させるアイデアを提案すること。\",\n",
    ")\n",
    "\n",
    "# Create the final reviewer agent\n",
    "progressive_agent3 = AssistantAgent(\n",
    "    \"progressive_agent3\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"あなたは生ける百科事典です。作成された文章を万物を理解している俯瞰的視点から評価し、作品背景をよりリッチで深みのあるものにするために提案すること。\",\n",
    ")\n",
    "\n",
    "# add agents to array\n",
    "progressive_agents: List[AssistantAgent] = [\n",
    "    progressive_agent1,\n",
    "    progressive_agent2,\n",
    "    progressive_agent3,\n",
    "]\n",
    "\n",
    "termination_condition = TextMessageTermination(\"progressive_agent3\") #3人目が発言したら終了\n",
    "progressive_team = RoundRobinGroupChat(progressive_agents, termination_condition=termination_condition)\n",
    "\n",
    "society_of_mind_agent1 = SocietyOfMindAgent(\"society_of_mind1\", team=critic_team, model_client=model_client)\n",
    "society_of_mind_agent2 = SocietyOfMindAgent(\"society_of_mind2\", team=progressive_team, model_client=model_client)\n",
    "\n",
    "\n",
    "# Create the final reviewer agent\n",
    "summary_agent = AssistantAgent(\n",
    "    \"summary_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"作成された文章を簡潔なあらすじにして出力すること。\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e32c5ae",
   "metadata": {},
   "source": [
    "# GraphFlow 定義\n",
    "並行ファンアウト/ファンインパターンを実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f91e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the workflow graph\n",
    "builder = DiGraphBuilder()\n",
    "builder.add_node(writer_agent).add_node(society_of_mind_agent1).add_node(society_of_mind_agent2).add_node(summary_agent)\n",
    "\n",
    "# Fan-out from writer to editor1 and editor2\n",
    "builder.add_edge(writer_agent, society_of_mind_agent1)\n",
    "builder.add_edge(writer_agent, society_of_mind_agent2)\n",
    "\n",
    "# Fan-in both editors into final reviewer\n",
    "builder.add_edge(society_of_mind_agent1, summary_agent)\n",
    "builder.add_edge(society_of_mind_agent2, summary_agent)\n",
    "\n",
    "# Build and validate the graph\n",
    "graph = builder.build()\n",
    "\n",
    "# Create the flow\n",
    "flow = GraphFlow(\n",
    "    participants=builder.get_participants(),\n",
    "    graph=graph,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd11bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow._participant_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead88b52",
   "metadata": {},
   "source": [
    "## グラフの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781ba436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo apt install graphviz -y\n",
    "#! pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac4a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "def visualize_digraph_graphviz(builder):\n",
    "    dot = graphviz.Digraph(comment=\"DiGraph Visualization\")\n",
    "    dot.attr(\n",
    "        rankdir=\"TB\",  # 上→下\n",
    "        nodesep=\"0.8\",  # ノード間隔\n",
    "        ranksep=\"0.5\",  # ランク間隔\n",
    "        edgesep=\"0.2\",  # エッジ間隔\n",
    "    )\n",
    "\n",
    "    for name, node in builder.nodes.items():\n",
    "        # 条件分岐ノード判定: 1つでもcondition付きエッジがあれば分岐ノードとみなす\n",
    "        is_conditional = any(getattr(edge, \"condition\", None) for edge in node.edges)\n",
    "        if is_conditional:\n",
    "            fill = \"pink\"  # 条件分岐ノードはオレンジ色\n",
    "        else:\n",
    "            fill = \"lightgreen\" if name == builder._default_start_node else \"lightblue\"\n",
    "        dot.node(name, name, style=\"filled\", fillcolor=fill)\n",
    "\n",
    "    for src, node in builder.nodes.items():\n",
    "        for edge in node.edges:\n",
    "            tgt = getattr(edge.target, \"name\", edge.target)\n",
    "            cond = edge.condition or \"\"\n",
    "            if cond:\n",
    "                dot.edge(\n",
    "                    src,\n",
    "                    tgt,\n",
    "                    label=cond,\n",
    "                    style=\"dashed\",\n",
    "                    minlen=\"1\",\n",
    "                    labeldistance=\"2.0\",\n",
    "                    labelangle=\"0\",\n",
    "                )\n",
    "            else:\n",
    "                dot.edge(src, tgt, style=\"solid\")\n",
    "    return dot\n",
    "\n",
    "# 使用例\n",
    "dot_graph = visualize_digraph_graphviz(builder)\n",
    "dot_graph  # セルの最後でオブジェクトを評価すると自動表示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8209c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"SocietyOfMindAgent\") as rollspan: # ルートスパンを作成\n",
    "    stream = flow.run_stream(task=\"SEが異世界に転生して無双する異世界転生系短編小説を書いてください。\")\n",
    "    await Console(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee7cee",
   "metadata": {},
   "source": [
    "## トレース解析から分かる実際のフロー"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3f86bc",
   "metadata": {},
   "source": [
    "![](./img/003.png)\n",
    "\n",
    "### SocietyOfMindAgent\n",
    "ソサイアティ・オブ・マインド（多重思考）の名前の通り、複数のエージェントが協働してまず内部で議論し、その議論の要旨をもとに最終的な回答だけを LLM に生成させるという役割を担うエージェントです。`SocietyOfMindAgent1` には 3つのエージェントを含む `RoundRobinGroupChat` を内部チームとして含めていますが、チームの議論終了後に `SocietyOfMindAgent` が議論の結果を集約するのがポイントです。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623ea90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen059",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
