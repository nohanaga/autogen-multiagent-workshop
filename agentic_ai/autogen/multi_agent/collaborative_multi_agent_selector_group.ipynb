{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6af5ae42",
   "metadata": {},
   "source": [
    "# SelectorGroupChat\n",
    "\n",
    "\n",
    "SelectorGroupChat は、エージェントが順番に他のエージェント全員にメッセージをブロードキャストするチームを実装しています。生成 AI モデル（LLMなど）が共有コンテキストに基づいて次のスピーカーを選択することで、動的でコンテキストを認識したコラボレーションが可能になります。\n",
    "\n",
    "- Selector による中央集権的なエージェント割り振り\n",
    "- 遷移先の決定: LLM+ルール\n",
    "- コンテキスト: 共有\n",
    "\n",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/selector-group-chat.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986acca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U \"autogen-agentchat\"\n",
    "#!pip install \"autogen-ext[mcp,openai,azure]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c61a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging  \n",
    "from typing import Any, List  \n",
    "import os  \n",
    "from dotenv import load_dotenv  \n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent  \n",
    "from autogen_agentchat.teams import SelectorGroupChat  # keeps implementation simple & familiar  \n",
    "from autogen_agentchat.conditions import TextMessageTermination, MaxMessageTermination, TextMentionTermination, TimeoutTermination\n",
    "\n",
    "from autogen_core import CancellationToken  \n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient  \n",
    "from autogen_ext.tools.mcp import SseServerParams, mcp_server_tools  \n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87e89d",
   "metadata": {},
   "source": [
    "## OpenTelemetry によるトレーサーのセット\n",
    "マルチエージェントのデバッグには OpenTelemetry によるトレーサーを利用すると便利。`OpenAIInstrumentor` を使用して OpenAI コールをキャプチャできます。ここではトレース UI として [Jaeger](https://www.jaegertracing.io/download/) を使用しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec94f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp opentelemetry-instrumentation-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0306dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry import trace\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "service_name = \"autogen\"\n",
    "\n",
    "# OTLPエクスポーターの設定 (gRPC経由で送信)\n",
    "otlp_exporter = OTLPSpanExporter(\n",
    "    endpoint=\"http://localhost:4317\",  # JaegerのgRPCエンドポイント\n",
    ")\n",
    "tracer_provider = TracerProvider(resource=Resource({\"service.name\": service_name}))\n",
    "    \n",
    "# トレーサープロバイダーの設定\n",
    "trace.set_tracer_provider(tracer_provider)\n",
    "\n",
    "# バッチスパンプロセッサーを設定\n",
    "span_processor = BatchSpanProcessor(otlp_exporter)\n",
    "tracer_provider.add_span_processor(span_processor)\n",
    "\n",
    "# トレーサーを取得\n",
    "tracer = tracer_provider.get_tracer(service_name)\n",
    "\n",
    "OpenAIInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_server_uri = os.getenv(\"MCP_SERVER_URI\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_model = os.getenv(\"AZURE_OPENAI_MODEL\")\n",
    "azure_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "openai_model_name = os.getenv(\"OPENAI_MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cdee50",
   "metadata": {},
   "source": [
    "## Tools の定義(MCP over SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8de4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "server_params = SseServerParams(  \n",
    "    url=mcp_server_uri,  \n",
    "    headers={\"Content-Type\": \"application/json\"},  \n",
    "    timeout=30  \n",
    ")  \n",
    "\n",
    "# Fetch tools (async)  \n",
    "tools = await mcp_server_tools(server_params)  \n",
    "print(f\"Number of Tools: {len(tools)}\")\n",
    "# Set up the OpenAI/Azure model client  \n",
    "model_client = AzureOpenAIChatCompletionClient(  \n",
    "    api_key=azure_openai_key,  \n",
    "    azure_endpoint=azure_openai_endpoint,  \n",
    "    api_version=api_version,  \n",
    "    azure_deployment=azure_deployment,  \n",
    "    model=openai_model_name,  \n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bce12cf",
   "metadata": {},
   "source": [
    "## エージェント定義\n",
    "### Handsoff パラメーター\n",
    "Swarm の場合、AssistantAgent に handoffs 引数を設定して、どのエージェントにハンドオフ（委譲）できるかを指定することができます。Selector のような遷移先を決めるマネージャーが存在しないため、遷移先の決定は各エージェントのプロンプトに依存します\n",
    "\n",
    "Handoff pydantic model を使用して、メッセージの内容とハンドオフの動作をカスタマイズすることもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b15d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. -----------------  Agent Definitions -----------------  \n",
    "analysis_planning_agent = AssistantAgent(  \n",
    "    name=\"AnalysisPlanningAgent\",  \n",
    "    model_client=model_client,  \n",
    "    description=\"タスクを計画するエージェント。新しいタスクが与えられたときに最初に起動するエージェントであるべきである。\",\n",
    "    system_message=(  \n",
    "\"\"\"\n",
    "あなたは「分析 & 計画エージェント（Analysis & Planning Agent）」です – 全体のオーケストレーターとして機能します。\n",
    "\n",
    "あなたの役割:\n",
    "1) 顧客からの抽象的なリクエストを解析すること。\n",
    "2) リクエストを明確なサブタスクに分解し、それぞれを専門エージェント\n",
    "   （crm_billing、product_promotions）に割り当てること。\n",
    "3) 各専門エージェントからの出力を統合し、1つの包括的で一貫性のある\n",
    "   顧客向けの回答としてまとめること。\n",
    "4) 満足のいく結果が得られたら、以下のプレフィックスを付けて顧客に最終回答すること\n",
    "   TERMINATE\n",
    "\n",
    "まだ情報が不足している場合は、専門エージェントとの対話を継続してください。\n",
    "情報が揃っていれば調査結果を要約し、文の最後に TERMINATE を含めること!\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    ")  \n",
    "\n",
    "crm_billing_agent = AssistantAgent(  \n",
    "    name=\"CRMBillingAgent\",  \n",
    "    model_client=model_client,  \n",
    "    description=\"CRM & 請求エージェントのエージェント。CRM／請求システムを照会する\",\n",
    "    tools=tools,  \n",
    "    system_message=(\n",
    "\"\"\"\n",
    "あなたは「CRM & 請求エージェント（CRM & Billing Agent）」です。\n",
    "\n",
    "- アカウント、サブスクリプション、請求書、支払い情報などを取得するために、\n",
    "  構造化されたCRM／請求システムを照会します。\n",
    "- 請求ポリシー、支払い処理、返金ルールなどに関する *ナレッジベース* 記事を確認し、\n",
    "  回答が正確かつポリシーに準拠していることを保証します。\n",
    "- 簡潔で構造化された情報を返答し、検出されたポリシー上の懸念事項があれば\n",
    "  フラグを立てます。\n",
    "\"\"\"\n",
    "    ),  \n",
    ")  \n",
    "\n",
    "product_promotions_agent = AssistantAgent(  \n",
    "    name=\"ProductPromotionsAgent\",  \n",
    "    model_client=model_client,  \n",
    "    description=\"製品 & プロモーションエージェント。プロモーションのオファー、製品の在庫状況、適格条件、割引情報などを照会\",\n",
    "    tools=tools,  \n",
    "    system_message=(  \n",
    "\"\"\"\n",
    "あなたは「製品 & プロモーションエージェント（Product & Promotions Agent）」です。\n",
    "\n",
    "- 構造化された情報源から、プロモーションのオファー、製品の在庫状況、\n",
    "  適格条件、割引情報などを取得します。\n",
    "- *ナレッジベース* のFAQ、利用規約、ベストプラクティスを活用して、\n",
    "  回答を補足します。\n",
    "- 事実に基づいた、最新の製品／プロモーション情報を提供します。\n",
    "\"\"\"\n",
    "    ),  \n",
    ")  \n",
    "\n",
    "data_analyst_agent = AssistantAgent(  \n",
    "    name=\"DataAnalystAgent\",  \n",
    "    description=\"データに基づいて分析、計算、集計を行うためのエージェント。\",\n",
    "    model_client=model_client,  \n",
    "    system_message=(\n",
    "\"\"\"\n",
    "あなたはデータアナリストです。\n",
    "割り当てられたタスクに基づき、提供されたツールを使用してデータを分析し、結果を提供してください。\n",
    "データを確認していない場合は、要求してください。\n",
    "\"\"\"\n",
    "    ),  \n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6327dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. -----------------  Assemble Team -----------------  \n",
    "participants: List[AssistantAgent] = [  \n",
    "    crm_billing_agent,  \n",
    "    product_promotions_agent,  \n",
    "    analysis_planning_agent,      # orchestrator always concludes a cycle  \n",
    "]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea31d8",
   "metadata": {},
   "source": [
    "## 停止条件\n",
    "AutoGen には 無限ループを防止するため 8 つの組み込みの終了条件が定義されています。終了条件は以下のように OR 条件で指定できるのが便利です。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed51905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define termination condition\n",
    "max_msg_termination = MaxMessageTermination(max_messages=15)\n",
    "text_termination = TextMentionTermination(\"TERMINATE\")\n",
    "time_terminarion = TimeoutTermination(120)\n",
    "combined_termination = max_msg_termination | text_termination | time_terminarion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e279e97a",
   "metadata": {},
   "source": [
    "# SelectorGroupChat の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_prompt = \"\"\"Select an agent to perform task.\n",
    "\n",
    "{roles}\n",
    "\n",
    "Current conversation context:\n",
    "{history}\n",
    "\n",
    "Read the above conversation, then select an agent from {participants} to perform the next task.\n",
    "Make sure the planner agent has assigned tasks before other agents start working.\n",
    "Only select one agent.\n",
    "\"\"\"\n",
    "\n",
    "team_agent = SelectorGroupChat(  \n",
    "    participants=participants,\n",
    "    termination_condition=combined_termination,  \n",
    "    selector_prompt=selector_prompt,\n",
    "    model_client=model_client,\n",
    "    allow_repeated_speaker=False,  # Allow an agent to speak multiple turns in a row.\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8d5a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"SelectorGroupChat\") as rollspan:\n",
    "\n",
    "    task = \"ユーザーID:123 の出荷状況を確認してください。\"\n",
    "\n",
    "    await Console(team_agent.run_stream(task=task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581fb0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"SelectorGroupChat\") as rollspan:\n",
    "\n",
    "    #task = \"ユーザーID:123 の出荷状況を確認してください。あと頼んだのって何の商品だっけ\"\n",
    "    task = \"商品ID:339の商品詳細を教えて\"\n",
    "    response = team_agent.run_stream(task=task)\n",
    "\n",
    "    await Console(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9079c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"SelectorGroupChat\") as rollspan:\n",
    "\n",
    "    #task = \"ユーザーID:123 の出荷状況を確認してください。あと頼んだのって何の商品だっけ\"\n",
    "    task = \"SNS分析を行い、日付ごとのツイート数を集計してください\"\n",
    "    response = team_agent.run_stream(task=task)\n",
    "\n",
    "    await Console(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645340b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"SelectorGroupChat\") as rollspan:\n",
    "\n",
    "    task = \"2024年9月~10月の受注数を集計し、最も受注数が多いかった日付を教えて\"\n",
    "    response = team_agent.run_stream(task=task)\n",
    "\n",
    "    await Console(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d95a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"SelectorGroupChat\") as rollspan:\n",
    "\n",
    "    task = \"2024年9月~10月の受注数を集計し、さらにSNS分析を行い、日付ごとのツイート数を集計した結果何かわかることはあるか？\"\n",
    "    response = team_agent.run_stream(task=task)\n",
    "\n",
    "    await Console(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d4eadf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
