{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f286d758",
   "metadata": {},
   "source": [
    "# Swarm\n",
    "\n",
    "Swarm は、エージェントが他のエージェントに能力に応じてタスクを委譲できるチームを実装しています。これは、OpenAI が実験プロジェクトで初めて導入したマルチエージェント設計パターンです。特別にセットされたツール（Function calling）を使用してエージェントが他のエージェントにタスクを委譲（Handoffs）できるようにすることです。これにより、エージェントは、SelectorGroupChat のような中央のオーケストレーターに頼らずに、エージェント遷移についてローカルで決定を下すことができます。\n",
    "\n",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/swarm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ec14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U \"autogen-agentchat\"\n",
    "#!pip install \"autogen-ext[mcp,openai,azure]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c61a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging  \n",
    "from typing import Any, List  \n",
    "import os  \n",
    "from dotenv import load_dotenv  \n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent  \n",
    "from autogen_agentchat.teams import Swarm  # keeps implementation simple & familiar  \n",
    "from autogen_agentchat.conditions import TextMessageTermination, MaxMessageTermination, TextMentionTermination, TimeoutTermination\n",
    "\n",
    "from autogen_core import CancellationToken  \n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient  \n",
    "from autogen_ext.tools.mcp import SseServerParams, mcp_server_tools  \n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54a1385",
   "metadata": {},
   "source": [
    "## OpenTelemetry によるトレーサーのセット\n",
    "マルチエージェントのデバッグには OpenTelemetry によるトレーサーを利用すると便利。`OpenAIInstrumentor` を使用して OpenAI コールをキャプチャできます。ここではトレース UI として [Jaeger](https://www.jaegertracing.io/download/) を使用しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d823abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp opentelemetry-instrumentation-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2087c39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry import trace\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "service_name = \"autogen\"\n",
    "\n",
    "# OTLPエクスポーターの設定 (gRPC経由で送信)\n",
    "otlp_exporter = OTLPSpanExporter(\n",
    "    endpoint=\"http://localhost:4317\",  # JaegerのgRPCエンドポイント\n",
    ")\n",
    "tracer_provider = TracerProvider(resource=Resource({\"service.name\": service_name}))\n",
    "    \n",
    "# トレーサープロバイダーの設定\n",
    "trace.set_tracer_provider(tracer_provider)\n",
    "\n",
    "# バッチスパンプロセッサーを設定\n",
    "span_processor = BatchSpanProcessor(otlp_exporter)\n",
    "tracer_provider.add_span_processor(span_processor)\n",
    "\n",
    "# トレーサーを取得\n",
    "tracer = tracer_provider.get_tracer(service_name)\n",
    "\n",
    "OpenAIInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_server_uri = os.getenv(\"MCP_SERVER_URI\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_model = os.getenv(\"AZURE_OPENAI_MODEL\")\n",
    "azure_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "openai_model_name = os.getenv(\"OPENAI_MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3210cca",
   "metadata": {},
   "source": [
    "## Tools の定義(MCP over SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8de4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "server_params = SseServerParams(  \n",
    "    url=mcp_server_uri,  \n",
    "    headers={\"Content-Type\": \"application/json\"},  \n",
    "    timeout=30  \n",
    ")  \n",
    "\n",
    "# Fetch tools (async)  \n",
    "tools = await mcp_server_tools(server_params)  \n",
    "print(f\"Number of Tools: {len(tools)}\")\n",
    "# Set up the OpenAI/Azure model client  \n",
    "model_client = AzureOpenAIChatCompletionClient(  \n",
    "    api_key=azure_openai_key,  \n",
    "    azure_endpoint=azure_openai_endpoint,  \n",
    "    api_version=api_version,  \n",
    "    azure_deployment=azure_deployment,  \n",
    "    model=openai_model_name,  \n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6a1cec",
   "metadata": {},
   "source": [
    "## エージェント定義\n",
    "### Handsoff パラメーター\n",
    "Swarm の場合、AssistantAgent に handoffs 引数を設定して、どのエージェントにハンドオフ（委譲）できるかを指定することができます。Selector のような遷移先を決めるマネージャーが存在しないため、遷移先の決定は各エージェントのプロンプトに依存します\n",
    "\n",
    "Handoff pydantic model を使用して、メッセージの内容とハンドオフの動作をカスタマイズすることもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b15d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. -----------------  Agent Definitions -----------------  \n",
    "coordinator = AssistantAgent(  \n",
    "    name=\"coordinator\",  \n",
    "    model_client=model_client,  \n",
    "    handoffs=[\"CRMBillingAgent\", \"ProductPromotionsAgent\"],\n",
    "    description=\"タスクを計画するエージェント。ユーザーのリクエストを適切な専門エージェントに振り分けてください。\",\n",
    "    system_message=(  \n",
    "\"\"\"\n",
    "あなたはコーディネーターです。ユーザーのリクエストを適切な専門エージェントに振り分けてください。\n",
    "質問に直接答えてはいけません。必ず適切なエージェントにルーティングしてください。\n",
    "- 請求やアカウント、CRM、SNS分析に関する質問は：CRMBillingAgent に振り分けること\n",
    "- 製品やプロモーションに関する質問は：ProductPromotionsAgent に振り分けること\n",
    "- 単純な質問に限り、直接回答しても構いません\n",
    "\n",
    "# Rule\n",
    "- Always send your coordinator first, then handoff to appropriate agent.\n",
    "- Always handoff to a single agent at a time.\n",
    "- 議論の結果を集約して最終的にユーザーに回答します。\n",
    "- 自分は専門エージェントを実行することはできません\n",
    "- handoff に失敗したら何度か再実行してください\n",
    "- すべての handsoff が終了し、最終回答が完成したら文の最後に TERMINATE を含めること!\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    ")  \n",
    "\n",
    "billing_agent = AssistantAgent(  \n",
    "    name=\"CRMBillingAgent\",  \n",
    "    model_client=model_client,  \n",
    "    description=\"CRM & 請求エージェントのエージェント。CRM／請求システムを照会する\",\n",
    "    tools=tools,  \n",
    "    handoffs=[\"coordinator\"],\n",
    "    system_message=(\n",
    "\"\"\"\n",
    "あなたは「CRM & 請求エージェント（CRM & Billing Agent）」です。\n",
    "\n",
    "- アカウント、サブスクリプション、請求書、支払い情報などを取得するために、\n",
    "  構造化されたCRM／請求システムを照会します。\n",
    "- 請求ポリシー、支払い処理、返金ルールなどに関する *ナレッジベース* 記事を確認し、\n",
    "  回答が正確かつポリシーに準拠していることを保証します。\n",
    "- 簡潔で構造化された情報を返答し、検出されたポリシー上の懸念事項があれば\n",
    "  フラグを立てます。\n",
    "- ツールを使って請求情報を確認してください。\n",
    "- 請求に関係ない質問は coordinator に振り分けてください。\n",
    "- Always handoff back to coordinator when analysis is complete.\n",
    "\"\"\"\n",
    "    ),  \n",
    ")  \n",
    "\n",
    "product_agent = AssistantAgent(  \n",
    "    name=\"ProductPromotionsAgent\",  \n",
    "    model_client=model_client,  \n",
    "    handoffs=[\"coordinator\"],\n",
    "    description=\"製品 & プロモーションエージェント。プロモーションのオファー、製品の在庫状況、適格条件、割引情報などを照会\",\n",
    "    tools=tools,  \n",
    "    system_message=(  \n",
    "\"\"\"\n",
    "あなたは「製品 & プロモーションエージェント（Product & Promotions Agent）」です。\n",
    "\n",
    "- 構造化された情報源から、プロモーションのオファー、製品の在庫状況、\n",
    "  適格条件、割引情報などを取得します。\n",
    "- *ナレッジベース* のFAQ、利用規約、ベストプラクティスを活用して、\n",
    "  回答を補足します。\n",
    "- 事実に基づいた、最新の製品／プロモーション情報を提供します。\n",
    "- ツールを使って製品やプロモーションの詳細を確認してください。\n",
    "- 製品に関係ない質問は coordinator に振り分けてください。\n",
    "- Always handoff back to coordinator when analysis is complete.\n",
    "\"\"\"\n",
    "    ),  \n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6327dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. -----------------  Assemble Team -----------------  \n",
    "participants: List[AssistantAgent] = [  \n",
    "    coordinator,  \n",
    "    billing_agent,  \n",
    "    product_agent\n",
    "]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca13a57",
   "metadata": {},
   "source": [
    "## 停止条件\n",
    "AutoGen には 無限ループを防止するため 8 つの組み込みの終了条件が定義されています。終了条件は以下のように OR 条件で指定できるのが便利です。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed51905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define termination condition\n",
    "max_msg_termination = MaxMessageTermination(max_messages=15)\n",
    "text_termination = TextMentionTermination(\"TERMINATE\")\n",
    "time_terminarion = TimeoutTermination(120)\n",
    "combined_termination = max_msg_termination | text_termination | time_terminarion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0268f2",
   "metadata": {},
   "source": [
    "## Swarm の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. -----------------  Create Team Agent -----------------\n",
    "team_agent = Swarm(\n",
    "    participants=participants,\n",
    "    termination_condition=combined_termination,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8d5a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"Swarm\") as rollspan: # ルートスパンを作成\n",
    "    task = \"ユーザーID:123 の出荷状況を確認してください。\"\n",
    "    await Console(team_agent.run_stream(task=task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581fb0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"Swarm\") as rollspan: # ルートスパンを作成\n",
    "    #task = \"ユーザーID:123 の出荷状況を確認してください。あと頼んだのって何の商品だっけ\"\n",
    "    task = \"商品ID:339の商品詳細を教えて\"\n",
    "    await Console(team_agent.run_stream(task=task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9079c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"Swarm\") as rollspan: # ルートスパンを作成\n",
    "#task = \"ユーザーID:123 の出荷状況を確認してください。あと頼んだのって何の商品だっけ\"\n",
    "    task = \"SNS分析を行い、日付ごとのツイート数を集計してください\"\n",
    "    await Console(team_agent.run_stream(task=task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645340b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"Swarm\") as rollspan: # ルートスパンを作成\n",
    "    task = \"2024年9月~10月の受注数を集計し、最も受注数が多いかった日付を教えて\"\n",
    "    await Console(team_agent.run_stream(task=task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d95a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"Swarm\") as rollspan: # ルートスパンを作成\n",
    "    task = \"2024年9月~10月の受注数を集計し、さらにSNS分析を行い、日付ごとのツイート数を集計した結果何かわかることはあるか？\"\n",
    "    await Console(team_agent.run_stream(task=task))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen059",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
