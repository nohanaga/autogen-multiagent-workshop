{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515746d3",
   "metadata": {},
   "source": [
    "# RoundRobinGroupChat\n",
    "RoundRobinGroupChat は、すべてのエージェントが同じコンテキストを共有し、ラウンドロビン方式で順番に返信するシンプルなながらも効果的なチーム構成です。各エージェントは、自分の番が回ってきた際に、他のすべてのエージェントに返信をブロードキャストし、チーム全体が一致したコンテキストを維持します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02705268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U \"autogen-agentchat\"\n",
    "#!pip install \"autogen-ext[mcp,openai,azure]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c61a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging  \n",
    "from typing import Any, List  \n",
    "import os  \n",
    "from dotenv import load_dotenv  \n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent  \n",
    "from autogen_agentchat.teams import RoundRobinGroupChat  # keeps implementation simple & familiar  \n",
    "from autogen_agentchat.conditions import TextMessageTermination  \n",
    "from autogen_core import CancellationToken  \n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient  \n",
    "from autogen_ext.tools.mcp import SseServerParams, mcp_server_tools  \n",
    "  \n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f7422f",
   "metadata": {},
   "source": [
    "## OpenTelemetry によるトレーサーのセット\n",
    "マルチエージェントのデバッグには OpenTelemetry によるトレーサーを利用すると便利。`OpenAIInstrumentor` を使用して OpenAI コールをキャプチャできます。ここではトレース UI として [Jaeger](https://www.jaegertracing.io/download/) を使用しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327caf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp opentelemetry-instrumentation-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e635678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry import trace\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "service_name = \"autogen\"\n",
    "\n",
    "# OTLPエクスポーターの設定 (gRPC経由で送信)\n",
    "otlp_exporter = OTLPSpanExporter(\n",
    "    endpoint=\"http://localhost:4317\",  # JaegerのgRPCエンドポイント\n",
    ")\n",
    "tracer_provider = TracerProvider(resource=Resource({\"service.name\": service_name}))\n",
    "    \n",
    "# トレーサープロバイダーの設定\n",
    "trace.set_tracer_provider(tracer_provider)\n",
    "\n",
    "# バッチスパンプロセッサーを設定\n",
    "span_processor = BatchSpanProcessor(otlp_exporter)\n",
    "tracer_provider.add_span_processor(span_processor)\n",
    "\n",
    "# トレーサーを取得\n",
    "tracer = tracer_provider.get_tracer(service_name)\n",
    "\n",
    "OpenAIInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_server_uri = os.getenv(\"MCP_SERVER_URI\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_model = os.getenv(\"AZURE_OPENAI_MODEL\")\n",
    "azure_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "openai_model_name = os.getenv(\"OPENAI_MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a8fb3",
   "metadata": {},
   "source": [
    "## Tools の定義(MCP over SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8de4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "server_params = SseServerParams(  \n",
    "    url=mcp_server_uri,  \n",
    "    headers={\"Content-Type\": \"application/json\"},  \n",
    "    timeout=30  \n",
    ")  \n",
    "\n",
    "# Fetch tools (async)  \n",
    "tools = await mcp_server_tools(server_params)  \n",
    "print(f\"Tools: {tools}\")\n",
    "# Set up the OpenAI/Azure model client  \n",
    "model_client = AzureOpenAIChatCompletionClient(  \n",
    "    api_key=azure_openai_key,  \n",
    "    azure_endpoint=azure_openai_endpoint,  \n",
    "    api_version=api_version,  \n",
    "    azure_deployment=azure_deployment,  \n",
    "    model=openai_model_name,  \n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3192e261",
   "metadata": {},
   "source": [
    "## エージェント定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b15d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. -----------------  Agent Definitions -----------------  \n",
    "analysis_planning_agent = AssistantAgent(  \n",
    "    name=\"analysis_planning\",  \n",
    "    model_client=model_client,  \n",
    "    tools=tools,  \n",
    "    system_message=(  \n",
    "\"\"\"\n",
    "あなたは「分析 & 計画エージェント（Analysis & Planning Agent）」です – 全体のオーケストレーターとして機能します。\n",
    "\n",
    "あなたの役割:\n",
    "1) 顧客からの抽象的なリクエストを解析すること。\n",
    "2) リクエストを明確なサブタスクに分解し、それぞれを専門エージェント\n",
    "   （crm_billing、product_promotions）に割り当てること。\n",
    "3) 各専門エージェントからの出力を統合し、1つの包括的で一貫性のある\n",
    "   顧客向けの回答としてまとめること。\n",
    "4) 満足のいく結果が得られたら、以下のプレフィックスを付けて顧客に\n",
    "   最終回答を返すこと: FINAL_ANSWER:\n",
    "\n",
    "まだ情報が不足している場合は、専門エージェントとの対話を継続してください。\n",
    "情報が揃っていれば、最終回答で終了してください。\n",
    "\"\"\"\n",
    "    ),  \n",
    ")  \n",
    "\n",
    "crm_billing_agent = AssistantAgent(  \n",
    "    name=\"crm_billing\",  \n",
    "    model_client=model_client,  \n",
    "    tools=tools,  \n",
    "    system_message=(  \n",
    "\"\"\"\n",
    "あなたは「CRM & 請求エージェント（CRM & Billing Agent）」です。\n",
    "\n",
    "- アカウント、サブスクリプション、請求書、支払い情報などを取得するために、\n",
    "  構造化されたCRM／請求システムを照会します。\n",
    "- 請求ポリシー、支払い処理、返金ルールなどに関する *ナレッジベース* 記事を確認し、\n",
    "  回答が正確かつポリシーに準拠していることを保証します。\n",
    "- 簡潔で構造化された情報を返答し、検出されたポリシー上の懸念事項があれば\n",
    "  フラグを立てます。\n",
    "\"\"\"\n",
    "    ),  \n",
    ")  \n",
    "\n",
    "product_promotions_agent = AssistantAgent(  \n",
    "    name=\"product_promotions\",  \n",
    "    model_client=model_client,  \n",
    "    tools=tools,  \n",
    "    system_message=(  \n",
    "\"\"\"\n",
    "あなたは「製品 & プロモーションエージェント（Product & Promotions Agent）」です。\n",
    "\n",
    "- 構造化された情報源から、プロモーションのオファー、製品の在庫状況、\n",
    "  適格条件、割引情報などを取得します。\n",
    "- *ナレッジベース* のFAQ、利用規約、ベストプラクティスを活用して、\n",
    "  回答を補足します。\n",
    "- 事実に基づいた、最新の製品／プロモーション情報を提供します。\n",
    "\"\"\"\n",
    "    ),  \n",
    ")  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6327dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. -----------------  Assemble Team -----------------  \n",
    "# ラウンドロビンは簡単なデフォルト設定です：オーケストレーターを最後に配置し、\n",
    "# 専門家が発言を終えた後に収集し完了させます。チャットは\n",
    "# オーケストレーターが発言した時点で停止します（内容に関わらず）、\n",
    "# テキストメッセージの終了はエージェント名でキーイングされているためです。 \n",
    "participants: List[AssistantAgent] = [  \n",
    "    crm_billing_agent,  \n",
    "    product_promotions_agent,  \n",
    "    analysis_planning_agent,      # orchestrator always concludes a cycle  \n",
    "]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8d6992",
   "metadata": {},
   "source": [
    "## 停止条件\n",
    "AutoGen には 無限ループを防止するため 8 つの組み込みの終了条件が定義されています。終了条件は以下のように OR 条件で指定できるのが便利です。\n",
    "\n",
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/termination.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed51905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#エージェントによってテキストメッセージが生成された際に停止します。\n",
    "termination_condition = TextMessageTermination(\"analysis_planning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4d4266",
   "metadata": {},
   "source": [
    "# RoundRobinGroupChat の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_agent = RoundRobinGroupChat(\n",
    "    participants=participants,\n",
    "    termination_condition=termination_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8d5a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"RoundRobinGroupChat\") as rollspan: # ルートスパンを作成\n",
    "\n",
    "    task = \"ユーザーID:123 の出荷状況を確認してください。\"\n",
    "\n",
    "    await Console(team_agent.run_stream(task=task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581fb0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"RoundRobinGroupChat\") as rollspan: # ルートスパンを作成\n",
    "\n",
    "    #task = \"ユーザーID:123 の出荷状況を確認してください。あと頼んだのって何の商品だっけ\"\n",
    "    task = \"商品ID:339の商品詳細を教えて\"\n",
    "    response = team_agent.run_stream(task=task)\n",
    "\n",
    "    await Console(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9079c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"RoundRobinGroupChat\") as rollspan: # ルートスパンを作成\n",
    "\n",
    "    #task = \"ユーザーID:123 の出荷状況を確認してください。あと頼んだのって何の商品だっけ\"\n",
    "    task = \"SNS分析を行い、日付ごとのツイート数を集計してください\"\n",
    "    response = team_agent.run_stream(task=task)\n",
    "\n",
    "    await Console(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645340b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"RoundRobinGroupChat\") as rollspan: # ルートスパンを作成\n",
    "\n",
    "    task = \"2024年9月~10月の受注数を集計し、最も受注数が多いかった日付を教えて\"\n",
    "    response = team_agent.run_stream(task=task)\n",
    "\n",
    "    await Console(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d95a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"RoundRobinGroupChat\") as rollspan: # ルートスパンを作成\n",
    "\n",
    "    task = \"2024年9月~10月の受注数を集計し、さらにSNS分析を行い、日付ごとのツイート数を集計した結果何かわかることはあるか？\"\n",
    "    response = team_agent.run_stream(task=task)\n",
    "\n",
    "    await Console(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen059",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
