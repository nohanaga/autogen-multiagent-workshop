{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "751acbb1",
   "metadata": {},
   "source": [
    "# RoundRobinGroupChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a58df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "from dotenv import load_dotenv  \n",
    "  \n",
    "from autogen_agentchat.agents import AssistantAgent  \n",
    "from autogen_agentchat.teams import RoundRobinGroupChat  \n",
    "from autogen_agentchat.conditions import TextMessageTermination  \n",
    "from autogen_core import CancellationToken  \n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient  \n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.tools.mcp import SseServerParams, mcp_server_tools  \n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0785d1e0",
   "metadata": {},
   "source": [
    "## OpenTelemetry によるトレーサーのセット\n",
    "マルチエージェントのデバッグには OpenTelemetry によるトレーサーを利用すると便利。`OpenAIInstrumentor` を使用して OpenAI コールをキャプチャできます。ここではトレース UI として [Jaeger](https://www.jaegertracing.io/download/) を使用しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d668f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opentelemetry import trace\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.instrumentation.openai import OpenAIInstrumentor\n",
    "\n",
    "service_name = \"autogen\"\n",
    "\n",
    "# OTLPエクスポーターの設定 (gRPC経由で送信)\n",
    "otlp_exporter = OTLPSpanExporter(\n",
    "    endpoint=\"http://localhost:4317\",  # JaegerのgRPCエンドポイント\n",
    ")\n",
    "tracer_provider = TracerProvider(resource=Resource({\"service.name\": service_name}))\n",
    "    \n",
    "# トレーサープロバイダーの設定\n",
    "trace.set_tracer_provider(tracer_provider)\n",
    "\n",
    "# バッチスパンプロセッサーを設定\n",
    "span_processor = BatchSpanProcessor(otlp_exporter)\n",
    "tracer_provider.add_span_processor(span_processor)\n",
    "\n",
    "# トレーサーを取得\n",
    "tracer = tracer_provider.get_tracer(service_name)\n",
    "\n",
    "OpenAIInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_server_uri = os.getenv(\"MCP_SERVER_URI\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_model = os.getenv(\"AZURE_OPENAI_MODEL\")\n",
    "azure_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "openai_model_name = os.getenv(\"OPENAI_MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f87740e",
   "metadata": {},
   "source": [
    "## Tools の定義(MCP over SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44297f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "server_params = SseServerParams(  \n",
    "    url=mcp_server_uri,  \n",
    "    headers={\"Content-Type\": \"application/json\"},  \n",
    "    timeout=30  \n",
    ")  \n",
    "\n",
    "# Fetch tools (async)  \n",
    "tools = await mcp_server_tools(server_params)  \n",
    "print(f\"Tools: {tools}\")\n",
    "# Set up the OpenAI/Azure model client  \n",
    "model_client = AzureOpenAIChatCompletionClient(  \n",
    "    api_key=azure_openai_key,  \n",
    "    azure_endpoint=azure_openai_endpoint,  \n",
    "    api_version=api_version,  \n",
    "    azure_deployment=azure_deployment,  \n",
    "    model=openai_model_name,  \n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cbc0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tools)  # Check the number of tools available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379005c4",
   "metadata": {},
   "source": [
    "## エージェント定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76b07d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the assistant agent  \n",
    "agent = AssistantAgent(  \n",
    "    name=\"ai_assistant\",  \n",
    "    model_client=model_client,  \n",
    "    tools=tools,  \n",
    "    system_message=(  \n",
    "        \"あなたは役立つアシスタントです。複数のツールを使用して情報を検索し、質問に回答することができます。\"  \n",
    "        \"利用可能なツールを確認し、必要に応じて使用してください。ユーザーが不明点がある場合は、確認のための質問をすることもできます。\"\n",
    "    )\n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77586de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 終了条件を設定します：エージェントが自身として応答した際に停止します。 \n",
    "termination_condition = TextMessageTermination(\"ai_assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85bc58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loop_agent = RoundRobinGroupChat(  \n",
    "    [agent],  \n",
    "    termination_condition=termination_condition,  \n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba0f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"RoundRobinGroupChat\") as rollspan: # ルートスパンを作成\n",
    "    task = \"ユーザーID:123 の出荷状況を確認してください。\"\n",
    "\n",
    "    await Console(loop_agent.run_stream(task=task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"RoundRobinGroupChat\") as rollspan: # ルートスパンを作成\n",
    "    task = \"2024年9月1日から2024年9月2日までの間の合計受注金額を教えてください。\"\n",
    "\n",
    "    await Console(loop_agent.run_stream(task=task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e315d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"RoundRobinGroupChat\") as rollspan: # ルートスパンを作成\n",
    "    task = \"ユーザー別のツイート数上位を取得し、上位3名を教えてください。\"\n",
    "\n",
    "    await Console(loop_agent.run_stream(task=task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ff6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"RoundRobinGroupChat\") as rollspan: # ルートスパンを作成\n",
    "    task = \"#ローゼたん のツイートって何件あるの？検索して\"\n",
    "\n",
    "    await Console(loop_agent.run_stream(task=task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32029e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tracer.start_as_current_span(\"RoundRobinGroupChat\") as rollspan: # ルートスパンを作成\n",
    "    task = \"時間帯別ツイートで一番多い時間帯はいつ？\"\n",
    "\n",
    "    await Console(loop_agent.run_stream(task=task))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
